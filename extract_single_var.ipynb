{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f1087-7b7c-44a5-b921-3a58bd0ac201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import iris\n",
    "from matplotlib import pyplot as plt, animation\n",
    "import datetime\n",
    "import warnings\n",
    "from dask.distributed import Client\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['UMDIR']='/g/data/access/projects/access/umdir/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e87a6-3368-4f34-a8d2-d35c8980c239",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef0526-a910-4b4b-b2fb-2ff06e2fb753",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_prefix=\"umnsa_cldrad_\"\n",
    "\n",
    "file_d=datetime.datetime.fromisoformat('2022-02-22T00:00:00')\n",
    "dir_d=datetime.datetime.fromisoformat('2022-02-22T00:00:00')\n",
    "endtime=datetime.datetime.fromisoformat('2022-03-07T19:00:00')\n",
    "file_td=datetime.timedelta(hours=1)\n",
    "dir_td=datetime.timedelta(hours=6)\n",
    "\n",
    "iso_dir_d=dir_d.strftime(\"%Y%m%dT%H00\")\n",
    "iso_file_d=file_d.strftime(\"%Y%m%dT%H00\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10c73909",
   "metadata": {},
   "source": [
    "### Function to constrain by cell method if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d75c41f-64d1-43fe-8f72-c14aa297075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_cell_method(x):\n",
    "    if not x.cell_methods: return False\n",
    "    return x.cell_methods[0].method == c.cell_methods[0].method\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8946081c",
   "metadata": {},
   "source": [
    "### Setup dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21218b88-5f45-4383-b8c5-0f88e9a63b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=Client(threads_per_worker=1)\n",
    "client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad6fd073-45c2-4d0c-b15e-b92a14b5600d",
   "metadata": {},
   "source": [
    "### Loop over all cubes from one file\n",
    "Note that this needs to be adapted depending on the file requirements. The code below outputs hourly data, however, this may need to be changed to daily, or over the whole duration of the experiment. The `all_cubes` variable is a remnant of this. In the case where the single-variable files should be longer than the UM output period, gather all `con_cubes` into the `all_cubes` list, then run `xr.concat` on the list and save that, with appropriate date stamps on the final netCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf4c86-d98b-4753-b775-0fc1273022e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cubes=iris.load(f'/g/data/hh5/tmp/WACI-Hackathon-2023/AUS2200/day1/{iso_dir_d}Z/aus2200/d0198/RA3/um/{file_prefix}{iso_file_d}')\n",
    "### Need to constrain by both name and cell_method, but cell_method sometimes doesn't exist.\n",
    "duplicate_stash=( \"m01s03i236\" ,'m01s03i460', 'm01s03i461', 'm01s03i234', 'm01s03i217','m01s03i223' )\n",
    "for c in cubes:\n",
    "    field_con=iris.AttributeConstraint(STASH=c.attributes['STASH'])\n",
    "    if ( str(c.attributes['STASH']) in duplicate_stash ) and c.cell_methods:\n",
    "        cell_method_con=iris.Constraint(cube_func=has_cell_method)\n",
    "        netcdf_name=f\"/scratch/v45/dr4292/single_field_netcdf/{c.name()}_{c.cell_methods[0].method}\"\n",
    "    else:\n",
    "        cell_method_con=None\n",
    "        netcdf_name=f\"/scratch/v45/dr4292/single_field_netcdf/{c.name()}\"\n",
    "\n",
    "    if os.path.isfile(netcdf_name): continue\n",
    "    #if c.name() == \"land_binary_mask\": continue\n",
    "    \n",
    "    file_d=datetime.datetime.fromisoformat('2022-02-22T00:00:00')\n",
    "    dir_d=datetime.datetime.fromisoformat('2022-02-22T00:00:00')\n",
    "    file_td=datetime.timedelta(hours=1)\n",
    "    dir_td=datetime.timedelta(hours=6)\n",
    "    iso_dir_d=dir_d.strftime(\"%Y%m%dT%H00\")\n",
    "    iso_file_d=file_d.strftime(\"%Y%m%dT%H00\")\n",
    "    counter=24\n",
    "    dayno=1\n",
    "    all_cubes=[]\n",
    "    con_cubes=[]\n",
    "    while dir_d < endtime:\n",
    "        all_cubes=[]\n",
    "        con_cubes=[]\n",
    "        iso_dir_d=dir_d.strftime(\"%Y%m%dT%H00\")\n",
    "        iso_file_d=file_d.strftime(\"%Y%m%dT%H00\")\n",
    "        con_cubes=iris.load(f'/g/data/hh5/tmp/WACI-Hackathon-2023/AUS2200/day{dayno}/{iso_dir_d}Z/aus2200/d0198/RA3/um/{file_prefix}{iso_file_d}',(field_con,cell_method_con))\n",
    "\n",
    "        con_cubes[0].remove_coord('forecast_period')\n",
    "        con_cubes[0].remove_coord('forecast_reference_time')\n",
    "        \n",
    "        ### .expand_dims('time') necessary for UM output with 1 timestep per file.\n",
    "        test=xr.DataArray.from_iris(con_cubes[0]).expand_dims('time')\n",
    "        \n",
    "        counter=counter+1\n",
    "        file_d=file_d+file_td\n",
    "        if counter > 24 and counter%6 == 0:\n",
    "            dir_d=dir_d+dir_td\n",
    "        if counter > 24 and counter%24 == 0:\n",
    "            dayno=dayno+1\n",
    "            \n",
    "        if c.attributes['STASH'] in (\"m01s08i225\",\"m01s08i223\"):\n",
    "            encoding={ \n",
    "                c.name(): {\n",
    "                'dtype':'float32',\n",
    "                #'zlib':True,\n",
    "                #'shuffle':True,\n",
    "                #'complevel':5,\n",
    "                'chunksizes': [14, 1, 212, 260 ]\n",
    "            }\n",
    "        }   \n",
    "        else:\n",
    "            encoding={ \n",
    "            c.name(): {\n",
    "                'dtype':'float32',\n",
    "    #            'zlib':True,\n",
    "    #            'shuffle':True,\n",
    "    #            'complevel':5,\n",
    "                'chunksizes': [14, 212, 260 ]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "        test.to_netcdf(netcdf_name + \"_\" + iso_file_d + \".nc\",encoding=encoding)\n",
    "        del(all_cubes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-22.10]",
   "language": "python",
   "name": "conda-env-analysis3-22.10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
